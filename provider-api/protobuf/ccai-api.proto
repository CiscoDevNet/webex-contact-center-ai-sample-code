/*
 This proto file has APIs for retrieving streaming content analyze responses from the the upstream
 For the streaming analyze content requests that is sent from orchestrator, relevant streaming
 analyze content response will be sent by the upstream connectors.
*/
syntax = "proto3";

package com.cisco.wcc.ccai.v1;

import  "com/cisco/wcc/ccai/v1/common/suggestions.proto";
import  "com/cisco/wcc/ccai/v1/common/recognize.proto";
import  "com/cisco/wcc/ccai/v1/common/messages.proto";
import  "com/cisco/wcc/ccai/v1/common/virtualagent.proto";
import  "com/cisco/wcc/ccai/v1/common/tts.proto";
import  "com/cisco/wcc/ccai/v1/common/utils.proto";

/*
 Type of the user - could be
 human agent,
 virtual agent or
 end user
*/
enum Role {

  ROLE_UNSPECIFIED = 0;
  HUMAN_AGENT = 1;
  AUTOMATED_AGENT = 2;
  END_USER = 3;
}

/*
 Type of the audio encoding - could be
 linear16,
 mulaw or
 alaw
*/
enum AudioEncoding {
  // Not specified.
  ENCODING_UNSPECIFIED = 0;
  // Uncompressed 16-bit signed little-endian samples (Linear PCM).
  LINEAR16 = 1; // TODO : Do we still need this, if not remove.
  // 8-bit samples that compound 14-bit audio samples using G.711 PCMU/mu-law.
  MULAW = 2;
  //alaw format
  ALAW = 3;
}

/*
 Represents the message for recognition config with audio encoding, sample rate hertz and language code
*/
message RecognitionConfig {
  AudioEncoding encoding = 1; //Type of audio encoding
  int32 sample_rate_hertz = 2; //sample rate in hertz
  string language_code = 3; //languate code

  //Channel number which has the caller stream in a multichannel file URL. Other streams will be considered as Agent Stream.
  //Default value will be based on RTMS usecase
  int32 caller_channel_number = 4;
  // Model definition to be used for recognition
  Model model=5;
}

/*
 Represents the streamingAnalyzeContentRequest message to be sent to the connectors with config/audio/text/dtmf information
*/
message StreamingAnalyzeContentRequest {
  //Input data could be audio, text, dtmf, event
  oneof InputData {
    bytes audio = 1; //audio
    string text = 2; //text
    DtmfEvents dtmf = 12; //dtmf
    InputEvent event = 13; //event
    //URL to stream the audio
    string url = 17;
  }

  RecognitionConfig inputAudioConfig = 3; // InputAudio Recognition Config

  bool interim_results = 4; //Is the interim results required?
  bool single_utterance = 5; //Is this a single utterance?


  string conversationId = 6;  //Unique conversationId. Callguid will be used as conversationId

  string roleId = 7; //CALLGUID + StreamId can form the global unique Id for tracking stream

  string ccaiConfigId = 8; //Indicates the global config id for services.

  Role role = 9; //Role specifying the type of user

  map<string, string> additionalInfo = 10; //Map to capture any additional or miscellaneous info

  string orgId = 11 ; //OrgId for supporting OrgId based access

  OutputAudioConfig outputAudioConfig = 14; //Output audio config

  enum RequestType {
    DEFAULT_UNSPECIFIED = 0; // Default Value
    VIRTUAL_AGENT = 1;      // Virtual Agent Request
    AGENT_ASSIST = 2;       // Agent Assist Request
  }

  RequestType requestType = 15; //Type of the request indicating the call stage at which the API is called.

  CmsConfig cmsConfig = 16; // passing cms config object to upstream services

  // start timestamp for the url based transcripts, epoch time in millis
  int64 urlTimestamp = 18;
}

/*
 Represents the Output audio config object
*/
message OutputAudioConfig {
  AudioConfig config = 1; //audio config
}

/*
 Represents the StreamingAnalyzeContentResponse object that is received from connector
*/
message StreamingAnalyzeContentResponse {
  StreamingRecognitionResult  recognition_result = 1 ; //Recognition result corresponding to a portion of the audio that is being processed
  AgentAnswerResult agentAnswerResult = 2; //Agent answer information for the audio being processed
  Message message = 3; //Message object with various attributes including timestamp and sentiment analysis
  string reply_text = 4 [deprecated = true]; //Reply text
  bytes reply_audio = 5 [deprecated = true]; //Reply audio, use VirtualAgentResult.Prompt.audio_content instead
  string reply_payload = 6 [deprecated = true]; //Reply payload
  VirtualAgentResult va_result = 7; //Response of Virtual Agent
}

/*
 Request message for the answer feedback
*/
message AnswerFeedbackRequest{
  AnswerRecord answer_record = 1; //Answer record for which the feedback to be obtained
  string ccaiConfigId = 2; //config id
  string orgId = 3 ; //OrgId for supporting OrgId based access
}

/*
 Returns only operation status for update operation.
*/
message AnswerFeedbackResponse {
  OperationStatus status = 1; //Status denoting unknown/success/failure
}

/*
 Represents the Answer record message with name and feedback information
*/
message AnswerRecord {
  string name = 1;    //Unique Answer record name
  AnswerFeedback answer_feedback = 2; //Answer feedback
}

/*
 Represents the Types of status to be included in the answer feedback response
*/
enum OperationStatus {
  UNKNOWN = 0; //type unknown
  SUCCESS = 1; //type success
  FAILURE = 2; //type failure
}

/*
 Type of the correctness level to be included in answers feedback
*/
enum CorrectnessLevel {
  CORRECTNESS_LEVEL_UNSPECIFIED = 0; //level unspecified
  NOT_CORRECT= 1; //not correct
  PARTIALLY_CORRECT = 2; //partially correct
  FULLY_CORRECT = 3; //fully correct
}

/*
 Represents the Answer Feedback message
*/
message AnswerFeedback {
  // Field to set the correctness level for answer record
  CorrectnessLevel correctness_level = 1;
  // to capture whether answer record is clicked or not
  bool clicked = 2;
  // to capture whether answer record displayed or not
  bool displayed = 3;
}


/*
 Analyze content service between orchestrator and connectors
*/
service AnalyzeContentService {
  //Bi-Directional Streaming API for streaming the audio content to connectors
  rpc StreamingAnalyzeContent(stream StreamingAnalyzeContentRequest) returns (stream StreamingAnalyzeContentResponse) {}

  // Set Feedback API
  rpc AnswerFeedback(AnswerFeedbackRequest) returns (AnswerFeedbackResponse) {}
}